import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration

def summarize_text(text, keyword):
    # Initialize the T5 model and tokenizer
    model = T5ForConditionalGeneration.from_pretrained("t5-base")
    tokenizer = T5Tokenizer.from_pretrained("t5-base")

    # Generate a summary of the text related to the keyword using the T5 model
    input_text = f"summarize: {text} related to {keyword}"
    input_ids = tokenizer.encode(input_text, return_tensors="pt", max_length=512, truncation=True)
    summary_ids = model.generate(input_ids, num_beams=4, max_length=100, length_penalty=2.0, early_stopping=True)
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

    # Return the summary as a string
    return summary
